---
title: "MFA 20222 Pre-programme Assignment"
author: "Edgar Pon"
date: "27/08/2021"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="my-biography" class="section level1">
<h1>My Biography</h1>
<p>My name is <em>Edgar Pon</em> and I’m from Lisbon and Macao. I have completed my bachelor’s degree in <strong>Economics</strong> last year and I lived in <em>Portugal</em>, <em>Macao</em> and <em>France</em>. I like a good balance between studying and partying and I enjoy having a good time, going out sometimes, having dinner and going to the pub.
I am fluent in:</p>
<ul>
<li>Portuguese</li>
<li>Cantonese</li>
<li>Mandarin</li>
</ul>
<p>In my free time, I enjoy watching (any kind of sports) and playing football, chess and board games.</p>
<p>To find out more about me, this is <a href="linkedin.com/in/edgar-pon">Linkedin</a> and my profile picture. <img src="https://media-exp1.licdn.com/dms/image/C4D03AQFLkCKLyGoqbw/profile-displayphoto-shrink_800_800/0/1542934443933?e=1636588800&amp;v=beta&amp;t=TqI9xebjuK0c-ncg6i7Q53I8fScwKGrPFharvWMkHug" alt="Pic" />.</p>
</div>
<div id="task-2-gapminder-country-comparison" class="section level1">
<h1>Task 2: <code>gapminder</code> country comparison</h1>
<p>In this analysis, I have the <code>gapminder</code> dataset that has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. To get a better look, I used glimpse function to see the variable names, variable types, etc.,
I also want to have a look at the first 20 rows of data.</p>
<pre class="r"><code>glimpse(gapminder)</code></pre>
<pre><code>## Rows: 1,704
## Columns: 6
## $ country   &lt;fct&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, ~
## $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~
## $ year      &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~
## $ lifeExp   &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~
## $ pop       &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~
## $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~</code></pre>
<pre class="r"><code>head(gapminder, 20) # look at the first 20 rows of the dataframe</code></pre>
<pre><code>## # A tibble: 20 x 6
##    country     continent  year lifeExp      pop gdpPercap
##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## 11 Afghanistan Asia       2002    42.1 25268405      727.
## 12 Afghanistan Asia       2007    43.8 31889923      975.
## 13 Albania     Europe     1952    55.2  1282697     1601.
## 14 Albania     Europe     1957    59.3  1476505     1942.
## 15 Albania     Europe     1962    64.8  1728137     2313.
## 16 Albania     Europe     1967    66.2  1984060     2760.
## 17 Albania     Europe     1972    67.7  2263554     3313.
## 18 Albania     Europe     1977    68.9  2509048     3533.
## 19 Albania     Europe     1982    70.4  2780097     3631.
## 20 Albania     Europe     1987    72    3075321     3739.</code></pre>
<p>I have created the <code>country_data</code>for Portugal and <code>continent_data</code> for Europe with the code below.</p>
<pre class="r"><code>country_data &lt;- gapminder %&gt;% 
            filter(country == &quot;Portugal&quot;) 

continent_data &lt;- gapminder %&gt;% 
            filter(continent == &quot;Europe&quot;)</code></pre>
<p>First, I plot life expectancy over the years for Portugal.</p>
<pre class="r"><code>plot1 &lt;- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
geom_point() +
geom_smooth(se = FALSE)+
NULL 

plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/lifeExp_one_country-1.png" width="672" /></p>
<p>And use <code>labs()</code> function to add an informative title to the plot.</p>
<pre class="r"><code>plot1&lt;- plot1 +
labs(title = &quot;Portugal Life Expectancy&quot;,
x = &quot;Year&quot;,
y = &quot;Life Expectancy&quot;) +
NULL


plot1</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/lifeExp_one_country_with_label-1.png" width="672" /></p>
<p>Next, I produce the plot for the european continent.</p>
<pre class="r"><code>ggplot(data=continent_data, mapping = aes(x = year , y = lifeExp , colour= country, group =country))+
geom_point() + 
geom_smooth(se = FALSE) +
NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/lifeExp_one_continent-1.png" width="672" /></p>
<p>Finally, I create graphs for all the continents and plot the life expectancy over time.</p>
<pre class="r"><code>ggplot(data = gapminder , mapping = aes(x = year , y = lifeExp , colour= continent))+
geom_point() + 
geom_smooth(se = FALSE) +
facet_wrap(~continent) +
theme(legend.position=&quot;none&quot;) + #remove all legends
NULL</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/lifeExp_facet_by_continent-1.png" width="672" /></p>
<p>After a thorough analysis, I came to the following conclusion.</p>
<blockquote>
<p>Type your answer after this blockquote.</p>
</blockquote>
<p>These graphs can be related to the evolution of demographic transition. One of the implications is that as economies develop and overall life quality improves, life expectancy tends to increase. All continents witnessed an increase in life expectancy, albeit at different growth rates and different age structures. Starting with the oceania and european continents, the most developed continents, the average life expectancy is the highest when compared to the other 3 continents. This result is expected due to improvements in healthcare and technology occurring in industrialized countries first. Moreover, in american and asian continents, a similar pattern is observable. However, as most of the countries in these two continents were not yet developed, the growth rate in life expectancy is expected to be higher than the rate in the already developed countries. Lastly, the african continent is the last continent to start the process of industrialization, but when compared to other continents, the growth rate of life expectancy seems to have stagnated in recent years, largely due to political failures, famine and lack of resources to improve living conditions.</p>
</div>
<div id="task-3-brexit-vote-analysis" class="section level1">
<h1>Task 3: Brexit vote analysis</h1>
<p>I will have a look at the results of the 2016 Brexit vote in the UK. First, I read the data using <code>read_csv()</code> and have a quick glimpse at the data</p>
<pre class="r"><code>brexit_results &lt;- read_csv(here::here(&quot;data&quot;,&quot;brexit_results.csv&quot;))


glimpse(brexit_results)</code></pre>
<pre><code>## Rows: 632
## Columns: 11
## $ Seat        &lt;chr&gt; &quot;Aldershot&quot;, &quot;Aldridge-Brownhills&quot;, &quot;Altrincham and Sale W~
## $ con_2015    &lt;dbl&gt; 50.592, 52.050, 52.994, 43.979, 60.788, 22.418, 52.454, 22~
## $ lab_2015    &lt;dbl&gt; 18.333, 22.369, 26.686, 34.781, 11.197, 41.022, 18.441, 49~
## $ ld_2015     &lt;dbl&gt; 8.824, 3.367, 8.383, 2.975, 7.192, 14.828, 5.984, 2.423, 1~
## $ ukip_2015   &lt;dbl&gt; 17.867, 19.624, 8.011, 15.887, 14.438, 21.409, 18.821, 21.~
## $ leave_share &lt;dbl&gt; 57.89777, 67.79635, 38.58780, 65.29912, 49.70111, 70.47289~
## $ born_in_uk  &lt;dbl&gt; 83.10464, 96.12207, 90.48566, 97.30437, 93.33793, 96.96214~
## $ male        &lt;dbl&gt; 49.89896, 48.92951, 48.90621, 49.21657, 48.00189, 49.17185~
## $ unemployed  &lt;dbl&gt; 3.637000, 4.553607, 3.039963, 4.261173, 2.468100, 4.742731~
## $ degree      &lt;dbl&gt; 13.870661, 9.974114, 28.600135, 9.336294, 18.775591, 6.085~
## $ age_18to24  &lt;dbl&gt; 9.406093, 7.325850, 6.437453, 7.747801, 5.734730, 8.209863~</code></pre>
<p>The data comes from <a href="https://www.thecrosstab.com/">Elliott Morris</a>, who cleaned it and made it available through his <a href="https://www.datacamp.com/courses/analyzing-election-and-polling-data-in-r">DataCamp class on analysing election and polling data in R</a>.</p>
<p>My main outcome variable (or y) is <code>leave_share</code>, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK <a href="https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies">parliament constituency</a>.</p>
<p>To get a sense of the spread, or distribution, of the data, I plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.</p>
<pre class="r"><code># histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5)+
  labs(title = &quot;Brexit Results&quot;, subtitle = &quot;Histogram Distribution&quot; ,caption = &quot;Source:Elliot Morris&quot;)+
  xlab (&quot;Born in UK&quot;) +
  ylab (&quot;Frequency&quot;)+
NULL</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/brexit_histogram-1.png" width="672" /></p>
<pre class="r"><code># density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density()+
  labs(title = &quot;Brexit Results&quot;,subtitle = &quot;Density Plot&quot;,
x = &quot;Leave Share&quot;,
y = &quot;Frequency&quot;) +
NULL</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/brexit_histogram-2.png" width="672" /></p>
<pre class="r"><code># The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)+
  labs(title = &quot;Brexit Results&quot;,subtitle = &quot;Cumulative Distribution Plot&quot;,
x = &quot;Leave Share&quot;,
y = &quot;Frequency&quot;) +
NULL</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/brexit_histogram-3.png" width="672" /></p>
<p>One common explanation for the Brexit outcome was fear of immigration and opposition to the EU’s more open border policy. I check the relationship (or correlation) between the proportion of native born residents (<code>born_in_uk</code>) in a constituency and its <code>leave_share</code>.</p>
<pre class="r"><code>brexit_results %&gt;% 
  select(leave_share, born_in_uk) %&gt;% 
  cor()</code></pre>
<pre><code>##             leave_share born_in_uk
## leave_share   1.0000000  0.4934295
## born_in_uk    0.4934295  1.0000000</code></pre>
<p>The correlation is almost 0.5, which shows that the two variables are positively correlated.</p>
<p>I also create a scatterplot between these two variables using <code>geom_point</code> and add the best fit line, using <code>geom_smooth(method = "lm")</code>.</p>
<pre class="r"><code>plot2&lt;-ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method=&quot;lm&quot; to get the best straight-line
  geom_smooth(method = &quot;lm&quot;) + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  labs(title = &quot;Brexit Immigration&quot;,subtitle = &quot;Scatter Plot&quot;,
x = &quot;Born in UK share&quot;,
y = &quot;Leave Share&quot;) +
NULL

plot2</code></pre>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/brexit_immigration_plot-1.png" width="672" /></p>
<p>In this section, I came to the following conclusion.</p>
<blockquote>
<p>Type your answer after, and outside, this blockquote.</p>
</blockquote>
<p>The scatter plot confirms that there is a positive relationship between UK-born residents in a constituency and voting to leave the EU. There is a cluster of data in the top right corner, hinting at a strong correlation between the two variables. However, some of the data is dispersed so it is not enough to prove causality. This is, some parliamentary constituencies, with either larger or smaller proportions of UK-born residents can vote ambiguously. An interesting study research should be used to analyze in which these parties are situated to have a better understanding of whether location influences the vote.</p>
</div>
<div id="task-4-animal-rescue-incidents-attended-by-the-london-fire-brigade" class="section level1">
<h1>Task 4: Animal rescue incidents attended by the London Fire Brigade</h1>
<p><a href="https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb">The London Fire Brigade</a> attends a range of non-fire incidents (which we call ‘special services’). These ‘special services’ include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.</p>
<p>Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv&quot;

animal_rescue &lt;- read_csv(url,
                          locale = locale(encoding = &quot;CP1252&quot;)) %&gt;% 
  janitor::clean_names()


glimpse(animal_rescue)</code></pre>
<pre><code>## Rows: 7,873
## Columns: 31
## $ incident_number               &lt;chr&gt; &quot;139091&quot;, &quot;275091&quot;, &quot;2075091&quot;, &quot;2872091&quot;~
## $ date_time_of_call             &lt;chr&gt; &quot;01/01/2009 03:01&quot;, &quot;01/01/2009 08:51&quot;, ~
## $ cal_year                      &lt;dbl&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009~
## $ fin_year                      &lt;chr&gt; &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/09&quot;, &quot;2008/0~
## $ type_of_incident              &lt;chr&gt; &quot;Special Service&quot;, &quot;Special Service&quot;, &quot;S~
## $ pump_count                    &lt;chr&gt; &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ pump_hours_total              &lt;chr&gt; &quot;2&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, &quot;1&quot;, ~
## $ hourly_notional_cost          &lt;dbl&gt; 255, 255, 255, 255, 255, 255, 255, 255, ~
## $ incident_notional_cost        &lt;chr&gt; &quot;510&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;, &quot;255&quot;~
## $ final_description             &lt;chr&gt; &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Redacted&quot;, &quot;Red~
## $ animal_group_parent           &lt;chr&gt; &quot;Dog&quot;, &quot;Fox&quot;, &quot;Dog&quot;, &quot;Horse&quot;, &quot;Rabbit&quot;, ~
## $ originof_call                 &lt;chr&gt; &quot;Person (land line)&quot;, &quot;Person (land line~
## $ property_type                 &lt;chr&gt; &quot;House - single occupancy&quot;, &quot;Railings&quot;, ~
## $ property_category             &lt;chr&gt; &quot;Dwelling&quot;, &quot;Outdoor Structure&quot;, &quot;Outdoo~
## $ special_service_type_category &lt;chr&gt; &quot;Other animal assistance&quot;, &quot;Other animal~
## $ special_service_type          &lt;chr&gt; &quot;Animal assistance involving livestock -~
## $ ward_code                     &lt;chr&gt; &quot;E05011467&quot;, &quot;E05000169&quot;, &quot;E05000558&quot;, &quot;~
## $ ward                          &lt;chr&gt; &quot;Crystal Palace &amp; Upper Norwood&quot;, &quot;Woods~
## $ borough_code                  &lt;chr&gt; &quot;E09000008&quot;, &quot;E09000008&quot;, &quot;E09000029&quot;, &quot;~
## $ borough                       &lt;chr&gt; &quot;Croydon&quot;, &quot;Croydon&quot;, &quot;Sutton&quot;, &quot;Hilling~
## $ stn_ground_name               &lt;chr&gt; &quot;Norbury&quot;, &quot;Woodside&quot;, &quot;Wallington&quot;, &quot;Ru~
## $ uprn                          &lt;chr&gt; &quot;NULL&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;100021491149.00~
## $ street                        &lt;chr&gt; &quot;Waddington Way&quot;, &quot;Grasmere Road&quot;, &quot;Mill~
## $ usrn                          &lt;chr&gt; &quot;20500146.00&quot;, &quot;NULL&quot;, &quot;NULL&quot;, &quot;21401484~
## $ postcode_district             &lt;chr&gt; &quot;SE19&quot;, &quot;SE25&quot;, &quot;SM5&quot;, &quot;UB9&quot;, &quot;RM3&quot;, &quot;RM~
## $ easting_m                     &lt;chr&gt; &quot;NULL&quot;, &quot;534785&quot;, &quot;528041&quot;, &quot;504689&quot;, &quot;N~
## $ northing_m                    &lt;chr&gt; &quot;NULL&quot;, &quot;167546&quot;, &quot;164923&quot;, &quot;190685&quot;, &quot;N~
## $ easting_rounded               &lt;dbl&gt; 532350, 534750, 528050, 504650, 554650, ~
## $ northing_rounded              &lt;dbl&gt; 170050, 167550, 164950, 190650, 192350, ~
## $ latitude                      &lt;chr&gt; &quot;NULL&quot;, &quot;51.39095371&quot;, &quot;51.36894086&quot;, &quot;5~
## $ longitude                     &lt;chr&gt; &quot;NULL&quot;, &quot;-0.064166887&quot;, &quot;-0.161985191&quot;, ~</code></pre>
<p>One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if I wanted to count the number of incidents by year, I would either use <code>group_by()... summarise()</code> or, simply <a href="https://dplyr.tidyverse.org/reference/count.html"><code>count()</code></a></p>
<pre class="r"><code>animal_rescue %&gt;% 
  dplyr::group_by(cal_year) %&gt;% 
  summarise(count=n())</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   648</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  count(cal_year, name=&quot;count&quot;)</code></pre>
<pre><code>## # A tibble: 13 x 2
##    cal_year count
##       &lt;dbl&gt; &lt;int&gt;
##  1     2009   568
##  2     2010   611
##  3     2011   620
##  4     2012   603
##  5     2013   585
##  6     2014   583
##  7     2015   540
##  8     2016   604
##  9     2017   539
## 10     2018   610
## 11     2019   604
## 12     2020   758
## 13     2021   648</code></pre>
<p>Let me try to see how many incidents we have by animal group. Again, I do this either using group_by() and summarise(), or by using count()</p>
<pre class="r"><code>animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %&gt;% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %&gt;% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3783   48.0 
##  2 Bird                              1631   20.7 
##  3 Dog                               1230   15.6 
##  4 Fox                                373    4.74
##  5 Unknown - Domestic Animal Or Pet   201    2.55
##  6 Horse                              195    2.48
##  7 Deer                               136    1.73
##  8 Unknown - Wild Animal               94    1.19
##  9 Squirrel                            68    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<pre class="r"><code>animal_rescue %&gt;% 
  
  #count does the same thing as group_by and summarise
  # name = &quot;count&quot; will call the column with the counts &quot;count&quot; ( exciting, I know)
  # and &#39;sort=TRUE&#39; will sort them from max to min
  count(animal_group_parent, name=&quot;count&quot;, sort=TRUE) %&gt;% 
  mutate(percent = round(100*count/sum(count),2))</code></pre>
<pre><code>## # A tibble: 28 x 3
##    animal_group_parent              count percent
##    &lt;chr&gt;                            &lt;int&gt;   &lt;dbl&gt;
##  1 Cat                               3783   48.0 
##  2 Bird                              1631   20.7 
##  3 Dog                               1230   15.6 
##  4 Fox                                373    4.74
##  5 Unknown - Domestic Animal Or Pet   201    2.55
##  6 Horse                              195    2.48
##  7 Deer                               136    1.73
##  8 Unknown - Wild Animal               94    1.19
##  9 Squirrel                            68    0.86
## 10 Unknown - Heavy Livestock Animal    50    0.64
## # ... with 18 more rows</code></pre>
<p>Do you see anything strange in these tables?</p>
<p>Normally, I would expect cats and dogs to be the top 2 animals to have incidents as they are often associated with these events. One would expect that cats would be at the top due to their agility. However, I was not expecting to observe birds have a higher count of incidents than dogs.</p>
<p>Finally, let us have a loot at the notional cost for rescuing each of these animals. As the LFB says,</p>
<blockquote>
<p>Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.</p>
</blockquote>
<p>There is two things I will do:</p>
<ol style="list-style-type: decimal">
<li>Calculate the mean and median <code>incident_notional_cost</code> for each <code>animal_group_parent</code></li>
<li>Plot a boxplot to get a feel for the distribution of <code>incident_notional_cost</code> by <code>animal_group_parent</code>.</li>
</ol>
<p>Before I go on, however, I need to fix <code>incident_notional_cost</code> as it is stored as a <code>chr</code>, or character, rather than a number.</p>
<pre class="r"><code># what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;character&quot;</code></pre>
<pre class="r"><code># readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue &lt;- animal_rescue %&gt;% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now &#39;double&#39; or numeric
typeof(animal_rescue$incident_notional_cost)</code></pre>
<pre><code>## [1] &quot;double&quot;</code></pre>
<p>Now tht incident_notional_cost is numeric, I calculate summary statistics for each animal group.</p>
<pre class="r"><code>animal_rescue %&gt;% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %&gt;% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()&gt;6) %&gt;% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %&gt;% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))</code></pre>
<pre><code>## # A tibble: 16 x 7
##    animal_group_parent      mean_incident_co~ median_incident_~ sd_incident_cost
##    &lt;chr&gt;                                &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;
##  1 Horse                                 740.               596            541. 
##  2 Cow                                   599.               436            451. 
##  3 Unknown - Wild Animal                 416.               333            322. 
##  4 Deer                                  415.               333            282. 
##  5 Unknown - Heavy Livesto~              374.               260            263. 
##  6 Fox                                   374.               328            205. 
##  7 Snake                                 356.               339            105. 
##  8 Dog                                   347.               298            168. 
##  9 Bird                                  344.               328            134. 
## 10 Cat                                   344.               326            160. 
## 11 Unknown - Domestic Anim~              326.               295            116. 
## 12 cat                                   324.               290             94.1
## 13 Hamster                               315.               290             95.0
## 14 Squirrel                              314.               326             56.7
## 15 Ferret                                309.               333             39.4
## 16 Rabbit                                309.               326             32.2
## # ... with 3 more variables: min_incident_cost &lt;dbl&gt;, max_incident_cost &lt;dbl&gt;,
## #   count &lt;int&gt;</code></pre>
<p>In the section below, I show what I found interesting in the analysis of this data.</p>
<p>The average cost seems to be higher than the median cost for most animals, meaning that there are some large costs(outliers) incurred in specific situations as confirmed with the maximum cost column. One specific intriguing fact is that the highest cost incurred belongs to the cat group, which one would usually not expect.</p>
<p>Finally, I plot the distribution of incident_cost for each animal group.</p>
<pre class="r"><code># base_plot
base_plot &lt;- animal_rescue %&gt;% 
  group_by(animal_group_parent) %&gt;% 
  filter(n()&gt;6) %&gt;% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = &quot;free&quot;)+
  theme_bw()

base_plot + geom_histogram()</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/plots_on_incident_cost_by_animal_group-1.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_density()</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/plots_on_incident_cost_by_animal_group-2.png" width="672" /></p>
<pre class="r"><code>base_plot + geom_boxplot()</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/plots_on_incident_cost_by_animal_group-3.png" width="672" /></p>
<pre class="r"><code>base_plot + stat_ecdf(geom = &quot;step&quot;, pad = FALSE) +
  scale_y_continuous(labels = scales::percent)</code></pre>
<p><img src="/blogs/Edgar_Pon_files/figure-html/plots_on_incident_cost_by_animal_group-4.png" width="672" /></p>
<p>In the section below, I show what I found in the analysis of this data.</p>
<p>The boxplot best illustrates the variability of the data set because the data distribution is visible across the plot and the outliers of each animal group.
Horses are the group with higher average costs than the rest of the animals, followed by cows and deers. One would typically assume the bigger the animal, the higher the difficulty (time, equipment, labor) to rescue them, thus a higher cost incurred. The personnel may have less experience dealing with larger animals, thus resulting in a longer period to successfully rescue a larger animal. This is observable through the distribution of animals of larger size. Smaller animals tend to be easier to rescue, therefore costs are substantially lower. As cats, birds and dogs have so many recurrent incidents, the fire brigade personnel already have the experience to deal with similar situations and in general, they should be of less complexity, which is the reason why most of the cases are within the quartiles and a small range.</p>
</div>
<div id="submit-the-assignment" class="section level1">
<h1>Submit the assignment</h1>
<p>Knit the completed R Markdown file as an HTML document (use the “Knit” button at the top of the script editor window) and upload it to Canvas.</p>
<div id="details" class="section level2">
<h2>Details</h2>
<p>If you want to, please answer the following</p>
<ul>
<li>Who did you collaborate with: Michael Huang MiM2022</li>
<li>Approximately how much time did you spend on this problem set: Datacamp courses around 6 hours, this assignment around 4-5 hours.</li>
<li>What, if anything, gave you the most trouble: My laptop does not knit the file in HTML. Have to manually write the Knit function.
rmarkdown::render(“Edgar_Pon.rmd”)</li>
</ul>
</div>
</div>
